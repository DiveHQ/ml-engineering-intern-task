{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "941c3be0-cf00-4a7d-bb9d-db2aead8b63a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T04:10:20.478905Z",
     "iopub.status.busy": "2023-05-11T04:10:20.478092Z",
     "iopub.status.idle": "2023-05-11T04:10:23.200889Z",
     "shell.execute_reply": "2023-05-11T04:10:23.199232Z",
     "shell.execute_reply.started": "2023-05-11T04:10:20.478883Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration, T5ForConditionalGeneration, BloomForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f3d764-75b8-49ae-a6e1-d66d538c5add",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T04:10:27.351040Z",
     "iopub.status.busy": "2023-05-11T04:10:27.350088Z",
     "iopub.status.idle": "2023-05-11T04:10:27.423289Z",
     "shell.execute_reply": "2023-05-11T04:10:27.422312Z",
     "shell.execute_reply.started": "2023-05-11T04:10:27.351009Z"
    }
   },
   "outputs": [],
   "source": [
    "from yaml.loader import SafeLoader\n",
    "import yaml\n",
    "from fuzzywuzzy import fuzz\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import *\n",
    "with open('../env.yml','r') as f:\n",
    "    data = yaml.load(f, Loader=SafeLoader)\n",
    "openai.organization = data[\"OPEN_API_ORG\"]\n",
    "openai.api_key = data[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a06fa64-1da9-4512-aed5-fd701d034ded",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T04:10:29.276010Z",
     "iopub.status.busy": "2023-05-11T04:10:29.275544Z",
     "iopub.status.idle": "2023-05-11T04:10:29.289783Z",
     "shell.execute_reply": "2023-05-11T04:10:29.287613Z",
     "shell.execute_reply.started": "2023-05-11T04:10:29.275982Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(action_true,action_pred):\n",
    "    \n",
    "    if not action_true and not action_pred:\n",
    "        return (1,0,0,0)\n",
    "    elif action_true and not action_pred:\n",
    "        return (0,0,1,0)\n",
    "    elif not action_true and action_pred:\n",
    "        return (0,0,0,1)\n",
    "    else:\n",
    "    \n",
    "        embed_1 = [get_embedding(item['text']) for item in action_true]\n",
    "        embed_2 = [get_embedding(item['text']) for item in action_pred]\n",
    "\n",
    "        scores = cos_sim(embed_1,embed_2)\n",
    "        top_idx = torch.argmax(scores,dim=1)\n",
    "        exact_match = 0\n",
    "        wrong_assignee = 0\n",
    "        not_found = 0\n",
    "        extra_generated = len(action_pred) - len(action_true) if len(action_pred) > len(action_true) else 0\n",
    "        for i,idx in enumerate(top_idx):\n",
    "            if scores[i][idx] > 0.85:\n",
    "                if fuzz.partial_ratio(action_true[i]['assignee'],action_pred[idx]['assignee']) >= 100:\n",
    "                    exact_match += 1\n",
    "                else:\n",
    "                    wrong_assignee += 1\n",
    "            else:\n",
    "                not_found += 1\n",
    "        metrics = [exact_match,wrong_assignee,not_found]\n",
    "        metrics = [x/len(action_true) for x in metrics] + [extra_generated]\n",
    "        return tuple(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5136eacd-3bed-494b-b99b-5ca7191f879e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T04:10:31.892914Z",
     "iopub.status.busy": "2023-05-11T04:10:31.892467Z",
     "iopub.status.idle": "2023-05-11T04:11:12.609154Z",
     "shell.execute_reply": "2023-05-11T04:11:12.608287Z",
     "shell.execute_reply.started": "2023-05-11T04:10:31.892884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7c4efac13d41068763883a66eacc0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/222 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c675e2192b445d866b57d4d1809415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/13.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3356fd650e74246b391c39ef0ee63dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ad0b6a41ea4ae0b1d7e6da88bb0a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/693 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954804b7a068457faef71d0bcff646d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Embedding(250681, 1024)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/datasets/dialogue.csv')\n",
    "df_train['id'] = df_train['id'].astype(str)\n",
    "\n",
    "\n",
    "with open('../data/datasets/labels.json','r') as f:\n",
    "    labels = json.load(f)\n",
    "\n",
    "model_name = \"bigscience/bloom-560m\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "if 't5' in model_name:\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "elif 'bloom' in model_name:\n",
    "    model = BloomForCausalLM.from_pretrained(model_name)\n",
    "else:\n",
    "    model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "tokenizer.add_tokens(['[SEP]'])\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a350e6bb-d11b-4213-b657-5d255c651a5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T04:11:16.420511Z",
     "iopub.status.busy": "2023-05-11T04:11:16.419186Z",
     "iopub.status.idle": "2023-05-11T04:11:17.722246Z",
     "shell.execute_reply": "2023-05-11T04:11:17.720950Z",
     "shell.execute_reply.started": "2023-05-11T04:11:16.420464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302.69117647058823\n",
      "463\n"
     ]
    }
   ],
   "source": [
    "# end = tokenizer.special_tokens_map['eos_token']\n",
    "idx = 0\n",
    "dataset = []\n",
    "dialogue_len = 0\n",
    "max_len = 0\n",
    "for i,item in enumerate(labels):\n",
    "    temp = {}\n",
    "    dialogues = df_train[df_train.id == item['id']][['speaker','text']].values\n",
    "    dialogues = [': '.join(x) for x in dialogues]\n",
    "    dialogue_str = '\\n'.join(dialogues)\n",
    "    if 't5' in model_name:\n",
    "        dialogue_str = 'Find Action Items from the following chat:\\n' + dialogue_str\n",
    "    if 'bloom' in model_name:\n",
    "        res = 'Action Item:\\n'+item['label']\n",
    "        res = res.replace('\\n','[SEP]')\n",
    "        dialogue_str = dialogue_str + '[SEP][SEP]' + res\n",
    "        temp['conversation'] = dialogue_str\n",
    "        temp['action_item'] = res\n",
    "    else:\n",
    "        temp['conversation'] = dialogue_str\n",
    "        temp['action_item'] = 'Action Item:\\n'+item['label']\n",
    "        temp['action_item'] = temp['action_item'].replace('\\n','[SEP]')\n",
    "    if len(tokenizer.encode(dialogue_str)) > 512:\n",
    "        continue\n",
    "    else:\n",
    "        dialogue_len += len(tokenizer.encode(dialogue_str))\n",
    "        if len(tokenizer.encode(dialogue_str.split(\"[SEP][SEP]\")[0])) > max_len:\n",
    "            max_len = len(tokenizer.encode(dialogue_str))\n",
    "        dataset.append(temp)\n",
    "print(dialogue_len/len(dataset))\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1559d0-184a-4706-b573-98af66f2d118",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T04:11:22.734070Z",
     "iopub.status.busy": "2023-05-11T04:11:22.733678Z",
     "iopub.status.idle": "2023-05-11T04:11:23.666537Z",
     "shell.execute_reply": "2023-05-11T04:11:23.665323Z",
     "shell.execute_reply.started": "2023-05-11T04:11:22.734070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb21402cb5154394aa6b36e9c2648e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/163 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3295e79a026e41f5b14ae11356e98268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/41 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels', 'genrate_input_ids'],\n",
       "        num_rows: 163\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels', 'genrate_input_ids'],\n",
       "        num_rows: 41\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_list(dataset)\n",
    "dataset_dict = dataset.train_test_split(test_size=0.2,seed = 2) \n",
    "# dataset_dict['test'].to_csv('test.csv') # Saving the data externally for testing\n",
    "# dataset_dict = dataset_dict[\"train\"].train_test_split(test_size=0.1,seed=2)\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(examples['conversation'],max_length=512, padding=\"max_length\")\n",
    "    \n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"action_item\"], max_length=256, padding=\"max_length\")\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    if \"bloom\" in model_name:\n",
    "        inp_text = [text.split(\"[SEP][SEP]\")[0] for text in examples['conversation']]\n",
    "        generation_tokens = tokenizer(inp_text,max_length=463, padding=\"max_length\")\n",
    "        model_inputs[\"genrate_input_ids\"] = generation_tokens[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = dataset_dict.map(preprocess_function, batched=True)\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['conversation','action_item'])\n",
    "\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0790b52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T04:11:24.177733Z",
     "iopub.status.busy": "2023-05-11T04:11:24.177324Z",
     "iopub.status.idle": "2023-05-11T04:11:24.184239Z",
     "shell.execute_reply": "2023-05-11T04:11:24.183285Z",
     "shell.execute_reply.started": "2023-05-11T04:11:24.177733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthew: Good morning everyone, let's start discussing our company-wide wellness program.\n",
      "Taylor: I think we should start with a survey to understand what our employees need and want in terms of wellness programs.\n",
      "Emily: That's a great idea, Taylor. We can use an online survey tool to collect the data.\n",
      "Matthew: Agreed. Once we have the data, we can prioritize the programs based on the needs of our employees.\n",
      "Taylor: I think we should also consider offering some mental health resources, like counseling or meditation classes.\n",
      "Emily: Yes, mental health is just as important as physical health. We can partner with local wellness centers to offer these resources.\n",
      "Matthew: That's a great idea, Emily. We can also consider offering fitness classes or gym memberships as part of the program.\n",
      "Taylor: I think we should also have a wellness challenge, like a step challenge or a healthy eating challenge, to encourage participation.\n",
      "Emily: That's a great idea, Taylor. We can offer prizes for the winners to make it more fun and engaging.\n",
      "Matthew: I think we should also have a budget for the program. We can allocate a certain amount per employee to cover the costs of the programs.\n",
      "Taylor: That's a good point, Matthew. We can also look for sponsorships or partnerships to help cover the costs.\n",
      "Emily: I think we should also have a timeline for the program, like a 6-month or 1-year program, to keep it focused and organized.[SEP][SEP]Action Item:[SEP]- Conduct an online survey to understand employee needs and wants||Taylor, Emily[SEP]- Prioritize wellness programs based on survey results||Matthew[SEP]- Partner with local wellness centers to offer mental health resources||Emily[SEP]- Consider offering fitness classes or gym memberships||Matthew[SEP]- Plan a wellness challenge with prizes for winners||Taylor, Emily[SEP]- Allocate a budget for the program and look for sponsorships or partnerships||Matthew, Taylor[SEP]- Set a timeline for the program||Emily\n"
     ]
    }
   ],
   "source": [
    "print(dataset_dict['test'][6]['conversation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f57d4cb-5c29-4630-b4d9-92ad5ef9a472",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T04:11:25.329916Z",
     "iopub.status.busy": "2023-05-11T04:11:25.329311Z",
     "iopub.status.idle": "2023-05-11T04:11:25.336728Z",
     "shell.execute_reply": "2023-05-11T04:11:25.335295Z",
     "shell.execute_reply.started": "2023-05-11T04:11:25.329863Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "train_dataloader = DataLoader(tokenized_datasets['train'], shuffle=True, batch_size=2)\n",
    "eval_dataloader = DataLoader(tokenized_datasets['test'], batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d239e88-7cf6-4ecf-a8fd-c05e8ca9367a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T04:11:26.890236Z",
     "iopub.status.busy": "2023-05-11T04:11:26.889688Z",
     "iopub.status.idle": "2023-05-11T04:11:33.270307Z",
     "shell.execute_reply": "2023-05-11T04:11:33.268986Z",
     "shell.execute_reply.started": "2023-05-11T04:11:26.890193Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 10\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "074e78c5-6473-4afd-b08a-f741571a98dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T04:11:36.422212Z",
     "iopub.status.busy": "2023-05-11T04:11:36.421538Z",
     "iopub.status.idle": "2023-05-11T04:12:02.889537Z",
     "shell.execute_reply": "2023-05-11T04:12:02.887790Z",
     "shell.execute_reply.started": "2023-05-11T04:11:36.422181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/training/wandb/run-20230511_041201-23emmp11</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/debalabbas7/action-item-extractor/runs/23emmp11\" target=\"_blank\">frosty-universe-24</a></strong> to <a href=\"https://wandb.ai/debalabbas7/action-item-extractor\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "run = wandb.init(\n",
    "  project=\"action-item-extractor\",\n",
    "  notes=\"architecture-comparisson\",\n",
    ")\n",
    "\n",
    "wandb.config = {\n",
    "\"epochs\" : num_epochs,\n",
    "\"train_batch_size\" : 2,\n",
    "\"model_architecture\" : \"bloom-560m\",\n",
    "\"pretraining_dataset\" : \"N/A\",   \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4085d11-b84a-4b70-bc1d-91789e2a3a1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T04:12:13.313676Z",
     "iopub.status.busy": "2023-05-11T04:12:13.312679Z",
     "iopub.status.idle": "2023-05-11T04:41:58.662140Z",
     "shell.execute_reply": "2023-05-11T04:41:58.660223Z",
     "shell.execute_reply.started": "2023-05-11T04:12:13.313637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc6516eaa3e464db50e7e2fac7e573d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train Loss:  0.9181063932143837\n",
      "Eval Loss:  0.9229989051818848\n",
      "Exact Match:  0.24285714285714285\n",
      "Wrong Assignee:  0.24308943089430896\n",
      "Not Found:  0.44088269454123113\n",
      "Extra Generated:  1.2926829268292683\n",
      "------------------------------\n",
      "Epoch 1\n",
      "Train Loss:  0.2805723613756566\n",
      "Eval Loss:  0.9517552909396944\n",
      "Exact Match:  0.31329849012775834\n",
      "Wrong Assignee:  0.24477351916376305\n",
      "Not Found:  0.3931475029036005\n",
      "Extra Generated:  0.2926829268292683\n",
      "------------------------------\n",
      "Epoch 2\n",
      "Train Loss:  0.1588135102043854\n",
      "Eval Loss:  1.0604251367705209\n",
      "Exact Match:  0.28792102206736353\n",
      "Wrong Assignee:  0.2576074332171894\n",
      "Not Found:  0.356910569105691\n",
      "Extra Generated:  0.8048780487804879\n",
      "------------------------------\n",
      "Epoch 3\n",
      "Train Loss:  0.09773156618230913\n",
      "Eval Loss:  1.202949773697626\n",
      "Exact Match:  0.29698025551684093\n",
      "Wrong Assignee:  0.2786875725900116\n",
      "Not Found:  0.3511614401858304\n",
      "Extra Generated:  0.4146341463414634\n",
      "------------------------------\n",
      "Epoch 4\n",
      "Train Loss:  0.05860561927769082\n",
      "Eval Loss:  1.314304184345972\n",
      "Exact Match:  0.3191637630662021\n",
      "Wrong Assignee:  0.22067363530778164\n",
      "Not Found:  0.36260162601626017\n",
      "Extra Generated:  0.5853658536585366\n",
      "------------------------------\n",
      "Epoch 5\n",
      "Train Loss:  0.035221844865866235\n",
      "Eval Loss:  1.531764995484125\n",
      "Exact Match:  0.3204413472706156\n",
      "Wrong Assignee:  0.2624854819976771\n",
      "Not Found:  0.3439024390243902\n",
      "Extra Generated:  0.6097560975609756\n",
      "------------------------------\n",
      "Epoch 6\n",
      "Train Loss:  0.023072054243983668\n",
      "Eval Loss:  1.6039039350691295\n",
      "Exact Match:  0.3173054587688734\n",
      "Wrong Assignee:  0.2682926829268293\n",
      "Not Found:  0.3412311265969803\n",
      "Extra Generated:  0.6829268292682927\n",
      "------------------------------\n",
      "Epoch 7\n",
      "Train Loss:  0.016747169733687412\n",
      "Eval Loss:  1.7245991201627822\n",
      "Exact Match:  0.33565621370499416\n",
      "Wrong Assignee:  0.2610917537746806\n",
      "Not Found:  0.33008130081300807\n",
      "Extra Generated:  0.6341463414634146\n",
      "------------------------------\n",
      "Epoch 8\n",
      "Train Loss:  0.014008699499207772\n",
      "Eval Loss:  1.793783255985805\n",
      "Exact Match:  0.3437862950058072\n",
      "Wrong Assignee:  0.2346689895470383\n",
      "Not Found:  0.3483739837398374\n",
      "Extra Generated:  0.6097560975609756\n",
      "------------------------------\n",
      "Epoch 9\n",
      "Train Loss:  0.01274217075548289\n",
      "Eval Loss:  1.8177373863401867\n",
      "Exact Match:  0.3437862950058072\n",
      "Wrong Assignee:  0.22653890824622527\n",
      "Not Found:  0.3565040650406504\n",
      "Extra Generated:  0.6097560975609756\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "\n",
    "def process_output(out_ids):\n",
    "    action_items = tokenizer.batch_decode(out_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    action_items = [x.split('[SEP]')[1:] for x in action_items]\n",
    "    final_preds = []\n",
    "    for item in action_items:\n",
    "        temp =  []\n",
    "        if item:\n",
    "            for action in item:\n",
    "                # print(action)\n",
    "                try:\n",
    "                    temp.append({'text':action.split('||')[0],'assignee':action.split('||')[1]})\n",
    "                except:\n",
    "                    continue\n",
    "        final_preds.append(temp)\n",
    "    return final_preds    \n",
    "\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        if \"bloom\" in model_name:\n",
    "            batch = {k: v.to(device) for k, v in batch.items() if k in ['input_ids','attention_mask']}\n",
    "            outputs = model(input_ids=batch[\"input_ids\"],\n",
    "                            attention_mask = batch[\"attention_mask\"],\n",
    "                            labels = batch[\"input_ids\"])\n",
    "        else:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "        torch.cuda.empty_cache()\n",
    "        # break\n",
    "    with torch.no_grad():\n",
    "        eval_loss = 0\n",
    "        exact_match = 0\n",
    "        wrong_assignee = 0\n",
    "        not_found = 0\n",
    "        extra_generated = 0\n",
    "        for batch in eval_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            if \"bloom\" in model_name:\n",
    "                outputs = model(input_ids=batch[\"input_ids\"],\n",
    "                                attention_mask = batch[\"attention_mask\"],\n",
    "                                labels = batch[\"input_ids\"])\n",
    "            else:\n",
    "                outputs = model(**batch)\n",
    "            eval_loss += outputs.loss.item()\n",
    "            \n",
    "            true_vals = process_output(batch[\"labels\"])\n",
    "            if \"bloom\" in model_name:\n",
    "                pred_ids = model.generate(batch[\"genrate_input_ids\"],max_length=512)\n",
    "            else:\n",
    "                pred_ids = model.generate(batch[\"input_ids\"],max_length=256)\n",
    "            pred_vals = process_output(pred_ids)\n",
    "            metrics = [evaluate(true_vals[i],pred_vals[i]) for i in range(batch['input_ids'].shape[0])]\n",
    "            metrics = [sum(i) for i in zip(*metrics)]\n",
    "            exact_match += metrics[0]\n",
    "            wrong_assignee += metrics[1]\n",
    "            not_found += metrics[2]\n",
    "            extra_generated += metrics[3]\n",
    "            # break\n",
    "            \n",
    "    print(f'Epoch {epoch}')\n",
    "    print('Train Loss: ',total_loss/len(dataset_dict['train']))\n",
    "    print('Eval Loss: ',eval_loss/len(eval_dataloader))\n",
    "    print('Exact Match: ', exact_match/(len(dataset_dict['test'])))\n",
    "    print('Wrong Assignee: ', wrong_assignee/(len(dataset_dict['test'])))\n",
    "    print('Not Found: ', not_found/(len(dataset_dict['test'])))\n",
    "    print('Extra Generated: ', extra_generated/(len(dataset_dict['test'])))\n",
    "    log_dict = {\n",
    "    \"train_loss\" : total_loss/len(dataset_dict['train']),\n",
    "    \"eval_loss\" :  eval_loss/len(eval_dataloader),\n",
    "    \"exact_match\" : exact_match/(len(dataset_dict['test'])),\n",
    "    \"wrong_assignee\" : wrong_assignee/(len(dataset_dict['test'])),\n",
    "    \"not_found\" : not_found/(len(dataset_dict['test'])),\n",
    "    'extra_generated' : extra_generated/(len(dataset_dict['test']))    \n",
    "    }\n",
    "    wandb.log(log_dict)\n",
    "    print(\"-\"*30)\n",
    "       \n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79ea5d11-3c7a-4deb-b44a-1a98ce219610",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T04:54:19.679949Z",
     "iopub.status.busy": "2023-05-11T04:54:19.678283Z",
     "iopub.status.idle": "2023-05-11T04:56:49.518311Z",
     "shell.execute_reply": "2023-05-11T04:56:49.516211Z",
     "shell.execute_reply.started": "2023-05-11T04:54:19.679899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match:  0.3643437862950058\n",
      "Wrong Assignee:  0.28583042973286876\n",
      "Not Found:  0.27665505226480835\n",
      "Extra Generated:  2.902439024390244\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "with torch.no_grad():\n",
    "        eval_loss = 0\n",
    "        exact_match = 0\n",
    "        wrong_assignee = 0\n",
    "        not_found = 0\n",
    "        extra_generated = 0\n",
    "        for batch in eval_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            # if \"bloom\" in model_name:\n",
    "            #     outputs = model(input_ids=batch[\"input_ids\"],\n",
    "            #                     attention_mask = batch[\"attention_mask\"],\n",
    "            #                     labels = batch[\"input_ids\"])\n",
    "            # else:\n",
    "            #     outputs = model(**batch)\n",
    "            # eval_loss += outputs.loss.item()\n",
    "            \n",
    "            true_vals = process_output(batch[\"labels\"])\n",
    "            if \"bloom\" in model_name:\n",
    "                pred_ids = model.generate(batch[\"genrate_input_ids\"],max_length=550)\n",
    "            else:\n",
    "                pred_ids = model.generate(batch[\"input_ids\"],max_length=256)\n",
    "            pred_vals = process_output(pred_ids)\n",
    "            metrics = [evaluate(true_vals[i],pred_vals[i]) for i in range(batch['input_ids'].shape[0])]\n",
    "            metrics = [sum(i) for i in zip(*metrics)]\n",
    "            exact_match += metrics[0]\n",
    "            wrong_assignee += metrics[1]\n",
    "            not_found += metrics[2]\n",
    "            extra_generated += metrics[3]\n",
    "        print('Exact Match: ', exact_match/(len(dataset_dict['test'])))\n",
    "        print('Wrong Assignee: ', wrong_assignee/(len(dataset_dict['test'])))\n",
    "        print('Not Found: ', not_found/(len(dataset_dict['test'])))\n",
    "        print('Extra Generated: ', extra_generated/(len(dataset_dict['test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "796cb980-3e44-4b3e-94fe-6e5b6b1aeb0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T04:51:40.444876Z",
     "iopub.status.busy": "2023-05-11T04:51:40.444457Z",
     "iopub.status.idle": "2023-05-11T04:51:51.105342Z",
     "shell.execute_reply": "2023-05-11T04:51:51.104404Z",
     "shell.execute_reply.started": "2023-05-11T04:51:40.444876Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        summary_ids = model.generate(batch[\"genrate_input_ids\"],max_length=768)\n",
    "        action_items = tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5efa2b19-1414-4b79-9d6f-e7973f192a64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T04:49:46.964783Z",
     "iopub.status.busy": "2023-05-11T04:49:46.964395Z",
     "iopub.status.idle": "2023-05-11T04:49:46.973902Z",
     "shell.execute_reply": "2023-05-11T04:49:46.972590Z",
     "shell.execute_reply.started": "2023-05-11T04:49:46.964783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(action_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b6f0833-aed7-40f1-be17-f0ff1370d5af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T04:51:57.220222Z",
     "iopub.status.busy": "2023-05-11T04:51:57.219543Z",
     "iopub.status.idle": "2023-05-11T04:51:57.234988Z",
     "shell.execute_reply": "2023-05-11T04:51:57.233358Z",
     "shell.execute_reply.started": "2023-05-11T04:51:57.220173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lauren: Good morning everyone, let's start with our market segmentation analysis meeting.\n",
      "Dylan: I have been researching the demographics of our target audience and have found that our product appeals mostly to young adults aged 18-35.\n",
      "Stephanie: I have been analyzing the psychographics of our target audience and have found that they value convenience and affordability.\n",
      "Matthew: I have been looking at the geographic distribution of our target audience and have found that they are mostly located in urban areas.\n",
      "Lauren: Great work everyone. Based on this information, we can create targeted marketing campaigns that focus on convenience and affordability for young adults in urban areas.\n",
      "Dylan: I also found that our target audience is mostly tech-savvy and spends a lot of time on social media.\n",
      "Stephanie: That's a great point, Dylan. We can use social media platforms to reach our target audience and promote our product.\n",
      "Matthew: I have also found that our target audience is interested in eco-friendly products and sustainability.\n",
      "Lauren: That's a great insight, Matthew. We can incorporate eco-friendliness and sustainability into our marketing campaigns to appeal to our target audience.\n",
      "Dylan: I think we should also consider partnering with influencers who align with our brand values and target audience.\n",
      "Stephanie: That's a great idea, Dylan. We can reach out to influencers who have a strong following among young adults and promote our product through them.\n",
      "Matthew: I will work on creating a list of potential influencers and their contact information.\n",
      "Lauren: Good morning everyone, let's start with our market segmentation analysis meeting.\n",
      "Dylan: I have been researching the demographics of our target audience and have found that our product appeals mostly to young adults aged 18-35.\n",
      "Stephanie: I have been analyzing the psychographics of our target audience and have found that they value convenience and affordability.\n",
      "Matthew: I have been looking at the geographic distribution of our target audience and have found that they are mostly located in urban areas.\n",
      "Lauren: Great work everyone. Based on this information, we can create targeted marketing campaigns that focus on convenience and affordability for young adults in urban areas.\n",
      "Dylan: I also found that our target audience is mostly tech-savvy and spends a lot of time on social media.\n",
      "Stephanie: That's a great point, Dylan. We can use social media platforms to reach our target audience and promote our product.\n",
      "Matthew: I have also found that our target audience is interested in eco-friendly products and sustainability.\n",
      "Lauren: That's a great insight, Matthew. We can incorporate eco-friendliness and sustainability into our marketing campaigns to appeal to our target audience.\n",
      "Dylan: I think we should also consider partnering with influencers who align with our brand values and target audience.\n",
      "Stephanie: That's a great idea, Dylan. We can reach out to influencers who have a strong following among young adults and promote our product through them.\n",
      "Matthew: I will work on creating a list of potential influencers and their contact information.\n",
      "\n",
      "Action Item:\n",
      "Create targeted marketing campaigns||Dylan,Stephanie\n",
      "Partner with influencers||Matthew\n",
      "Create a list of potential influencers and their contact information||Dylan,Stephanie\n",
      "Create a marketing plan||Matthew\n",
      "Review and adjust the marketing plan||Dylan,Stephanie\n",
      "Ensure the marketing plan is effective||Matthew\n",
      "Review and adjust the marketing plan||Dylan,Stephanie\n",
      "Ensure the marketing plan is comprehensive and includes all the necessary elements||Matthew\n",
      "Review and adjust the marketing plan||Dylan,Stephanie\n",
      "Ensure the marketing plan is up to date and includes all the necessary changes||Matthew\n",
      "Review and adjust the marketing plan||Dylan,Stephanie\n",
      "Ensure the marketing plan is comprehensive and includes all the necessary changes||Matthew\n",
      "Review and adjust the marketing plan||Dylan,Stephanie\n",
      "Ensure the marketing plan is up-to-date and includes all the necessary changes||Matthew\n",
      "Review and adjust the marketing plan||Dylan,Stephanie\n",
      "Ensure the marketing plan is comprehensive and includes all the necessary changes||Matthew\n",
      "Review and adjust the marketing plan||Dylan,Stephanie\n",
      "Ensure the marketing plan is up-to-date and includes all the necessary changes||Matthew\n",
      "Review and adjust the marketing plan||Dylan,Stephanie\n",
      "Ensure the marketing plan is comprehensive and includes all the necessary changes||Matthew\n",
      "Review and adjust the marketing plan||Dylan,Stephanie\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset_dict['test'][0]['conversation'].split('[SEP][SEP]')[0])\n",
    "# print(dataset_dict['test'][6]['action_item'])\n",
    "print(action_items[0].replace('[SEP]','\\n'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e9008d1-6faa-490c-9fe6-da83a72f1b59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T05:04:12.203582Z",
     "iopub.status.busy": "2023-05-11T05:04:12.202705Z",
     "iopub.status.idle": "2023-05-11T05:04:17.612607Z",
     "shell.execute_reply": "2023-05-11T05:04:17.611029Z",
     "shell.execute_reply.started": "2023-05-11T05:04:12.203550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../artifacts/bloom-560m-action-items/tokenizer_config.json',\n",
       " '../artifacts/bloom-560m-action-items/special_tokens_map.json',\n",
       " '../artifacts/bloom-560m-action-items/tokenizer.json')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('../artifacts/bloom-560m-action-items')\n",
    "tokenizer.save_pretrained('../artifacts/bloom-560m-action-items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81970abf-03ae-4238-b729-08e102f9e133",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface-cli repo create bloom-560m-action-items"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "dace3da8cecaa1df23d0950c50ea440e3b2967991b90a0a205455f6d2e2a07fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
